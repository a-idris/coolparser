
Implemented a predictive recursive descent parser for the Cool language. As per the specification there is error
recovery and .
Based on the grammar given in the language in the specification, it was necessary to transform the grammar.
Tried to convert to a LL(1) grammar.
The first steps were to remove the regex shortenings given in the grammar.
Then I removed the left recursion. Removed the direct recursion following the algorithm. Didn't use the algorithm
for indirect recursion; instead I manually inspected the grammar to check the grammar and made sure that there wasn't
any indirect left recursion by mentally following the different productions and seeing the ways it was possible for
them to expand.
Once it was in this form it was suitable for top down parsing, and it would be possible to write a backtracking parser
for it. However, I decided to go with the predictive parser because it is more efficient, and it makes the error detection/ recovery phase
more simple.
I then left factored the grammar. Left factoring is . Then I calculated the FIRST, FOLLOW and FIRST+ sets.
I encountered an issue.

modify grammar so it can be top down parsed w/out backtracking.

backtracking easier to implement, but less efficient. Run time of backtrack free is linear wrt sentence length, whereas
w/ backtracking it can be have on^2 growth (?) pg 98 algo
'Backtracking
increases the asymptotic cost of parsing; in practice, it is an expensive
way to discover syntax errors.' pg97

eliminate left recursion so top down parsing is possible. a backtracking solution would work at this point, albeit inefficiently. then doing predictive just makes it more efficient.

'The major source of inefficiency in the leftmost, top-down parser arises from
its need to backtrack.' pg 103


Necessary to convert the grammar to ll(1) form. Can confirm by checking for conflicts whether it is in fact in ll(1) form.

difficulty
	in lexing
		wanted to use shlexing completely, it would split based on alnum words or symbols e.g. id(id2) would split correctly as id, (, id2, ). however, it would split token symbol <= as <, =. Couldn't figure out an easy solution so had to 
		revert to shlex's whitespace split only, ie id(id2) would be passed as one string from shlex's gettoken and then do partial matches based on the token_patterns. the longest should win - maximal munch. then pass that partial to the parser and put the remainder back onto the shlex stack w/ pushtoken. had some issues w/ maximal munch. however, i really only bneeded to solve it for operators e.g. ->, -, >. i used an ordereddict so that rules considered in some order. if i put the 'longest' rule first, it should alwatys get the longest munch and thus be correct. only had to worry about tokens because  the others were disjoint. also, bvy default it's greedy so if the longest rule gets it then it will get the longest tokjen,.

		had some issues reconciling length precednece w/ operator prcedence. e.g. - is higher precedence than -> but -> is a longer rule.
		
		
		the way shlex handles strings. doesn't recognise quotes when it's part of a word. e.g. won't discern word"string"word. usually strings are in between punctuation, but if it encounters 
		
		drawback - doesn't preserve whitespace in strings.but since only concerned with syntax in this assignment, considered a necessary

parsing
    needed to convert the grammar first to not use the regexp shortened form in the manual figure

    then eliminated left recursion
        eliminated direct left recursion. thought through the grammar and determined that there is no indirect left recursion (by dfs). thus decided
        not to do the algorithm for eliminating indirect left recursion since my grammar was already fairly large and e.g. eliminating epsilon rules greatly
        increases grammar size.


testing
    individually tested lexing w/ the different example cool files to make sure the output was sensible.

trouble adding precedence. at first i moved the expr expansions not mentioned in the precedence diagram to the lowest precedence level
but this lead to a FIRST+ conflict, because at the highest precedence level I expanded to object_id, and had expansions starting w/ object_id
at the lowest level. But moving to the lowest precedence level solved it.

do ll(k) instead of backtracking since it makes error reporting easier. if ,ethod fails then know parse has failed, and can pass error messages


ambiguous about where to place the operators in expr that weren't listed on the precedence figure. I placed them all at the lowest level but then needed to move
ID ( EXPR_LIST ) to the highest level.


moving the other expressions to element introduced first+ conflicts, since now FOLLOW(ELEMENT) in FOLLOW(EXPR). this propagates down the levels. so, for each
operator for example there is a conflict. first+(epsilon) contains the operator.

'The <expr> of a let extends as far (encompasses as many tokens) as the grammar allows.
This means there can be no ambiguity such as: LET_EXPR + id
LET_EXPR will consume id.
The conflicts that let_expr introduces in the first_plus sets of operators can thus be ignored because of this behaviour.
Thus always give precedence to the more specific rule. e.g. + MULT_EXPR ADD_OP
instead of eps ALWAYS even though + is in FIRST_PLUS set of eps.