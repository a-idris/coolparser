modify grammar so it can be top down parsed w/out backtracking.

backtracking easier to implement, but less efficient. Run time of backtrack free is linear wrt sentence length, whereas
w/ backtracking it can be have on^2 growth (?) pg 98 algo
'Backtracking
increases the asymptotic cost of parsing; in practice, it is an expensive
way to discover syntax errors.' pg97

eliminate left recursion so top down parsing is possible. a backtracking solution would work at this point, albeit inefficiently. then doing predictive just makes it more efficient.

'The major source of inefficiency in the leftmost, top-down parser arises from
its need to backtrack.' pg 103


Necessary to convert the grammar to ll(1) form. Can confirm by checking for conflicts whether it is in fact in ll(1) form.

difficulty
	in lexing
		wanted to use shlexing completely, it would split based on alnum words or symbols e.g. id(id2) would split correctly as id, (, id2, ). however, it would split token symbol <= as <, =. Couldn't figure out an easy solution so had to 
		revert to shlex's whitespace split only, ie id(id2) would be passed as one string from shlex's gettoken and then do partial matches based on the token_patterns. the longest should win - maximal munch. then pass that partial to the parser and put the remainder back onto the shlex stack w/ pushtoken. had some issues w/ maximal munch. however, i really only bneeded to solve it for operators e.g. ->, -, >. i used an ordereddict so that rules considered in some order. if i put the 'longest' rule first, it should alwatys get the longest munch and thus be correct. only had to worry about tokens because  the others were disjoint. also, bvy default it's greedy so if the longest rule gets it then it will get the longest tokjen,.

		had some issues reconciling length precednece w/ operator prcedence. e.g. - is higher precedence than -> but -> is a longer rule.
		
		
		the way shlex handles strings. doesn't recognise quotes when it's part of a word. e.g. won't discern word"string"word. usually strings are in between punctuation, but if it encounters 
		
		drawback - doesn't preserve whitespace in strings.but since only concerned with syntax in this assignment, considered a necessary

parsing
    needed to convert the grammar first to not use the regexp shortened form in the manual figure

    then eliminated left recursion
        eliminated direct left recursion. thought through the grammar and determined that there is no indirect left recursion (by dfs). thus decided
        not to do the algorithm for eliminating indirect left recursion since my grammar was already fairly large and e.g. eliminating epsilon rules greatly
        increases grammar size.


testing
    individually tested lexing w/ the different example cool files to make sure the output was sensible.

trouble adding precedence. at first i moved the expr expansions not mentioned in the precedence diagram to the lowest precedence level
but this lead to a FIRST+ conflict, because at the highest precedence level I expanded to object_id, and had expansions starting w/ object_id
at the lowest level. But moving to the lowest precedence level solved it.

